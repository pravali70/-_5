# -*- coding: utf-8 -*-
"""SALES PREDICTION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HgIBDozhL7Gp8rQi26_C3lvC7hcPQSew
"""

# Importing libraries
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import seaborn as sns
import matplotlib.pyplot as plt
import ipywidgets as widgets
from IPython.display import display

from google.colab import drive
drive.mount('/content/drive')

df=pd.read_csv("/content/drive/MyDrive/Advertising.csv")
df=df.drop('Unnamed: 0', axis=1)
df

df.info()

#Checking entries and colimn number
df.shape

#Checking for null values
df.isnull().sum()

# Displaying General stats
df.describe()

# Printing columns
df.keys()

# Calculate the correlation matrix between all columns
correlation_matrix = df.corr()

# Create a heatmap of the correlation matrix
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.show()

# Create a line chart of each column with 'Sales'
for col in df.columns:
    if col != 'Sales':
        plt.plot(df[col], df['Sales'], 'o')
        plt.xlabel(col)
        plt.ylabel('Sales')
        plt.show()

import numpy as np
# Drop any additional columns besides 'TV', 'Radio', 'Newspaper', and 'Sales'
df = df[['TV', 'Radio', 'Newspaper', 'Sales']]

# Add polynomial terms for 'TV' and 'Radio'
df['TV_sq'] = df['TV']**2
df['Radio_sq'] = df['Radio']**2

# Add interaction term for 'TV' and 'Radio'
df['TV_Radio'] = df['TV'] * df['Radio']

# Create the feature matrix with the original features, polynomial terms, and interaction terms
X = df[['TV', 'Radio', 'Newspaper', 'TV_sq', 'Radio_sq', 'TV_Radio']]

# Create the y dataframe with the sales data
y = df[['Sales']].values

# Split the data into training and testing sets
X = df.drop('Sales', axis=1)
y = df['Sales']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Fit a linear regression model with the interaction and polynomial terms as features
model = LinearRegression()
model.fit(X_train, y_train)

# Evaluate the performance of the model on the testing data
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print('Mean squared error:', mse)

from sklearn.preprocessing import StandardScaler

# Define the scaler
scaler = StandardScaler()

# Scale the data
scaled_data = scaler.fit_transform(df[['TV', 'Radio', 'Newspaper','TV_sq', 'Radio_sq', 'TV_Radio']])

# Use the scaled data to fit the model and make predictions
X_train, X_test, y_train, y_test = train_test_split(scaled_data, df['Sales'], test_size=0.3, random_state=42)

# create new data to predict on
new_data = [[100, 50, 25, 10000, 2500, 625]] # TV = 100, Radio = 50, Newspaper = 25

# apply the same scaler used on the training data
new_data_scaled = scaler.transform(new_data)

# pass the preprocessed new data to the model for prediction
y_pred = model.predict(new_data_scaled)

print("Predicted Sales: ", y_pred[0])

